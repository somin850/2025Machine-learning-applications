# ğŸ“„ main_wosimilar.py
"""
Image Search í”„ë¡œì íŠ¸ ë©”ì¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ (ìœ ì‚¬ ì˜ˆì‹œ ì—†ì´)
ìœ ì‚¬í•œ ì´ë¯¸ì§€ ê²€ìƒ‰ ì—†ì´ ë°”ë¡œ ì´ë¯¸ì§€ë§Œìœ¼ë¡œ VLMì— ì „ë‹¬í•˜ì—¬ ìº¡ì…˜ì„ ìƒì„±í•©ë‹ˆë‹¤.
CUDA ì§€ì› ë° VLM_captions.json í˜•ì‹ ì¶œë ¥
"""

import os
import json
from datetime import datetime
import torch
import config

# OpenMP ì˜¤ë¥˜ í•´ê²°
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'
from dataset_loader import load_and_split_dataset
from image_embedder import build_image_embedding_db
from vlm_captioner import create_vlm_captioner
from db_manager import create_database_manager, initialize_databases_from_training_data


def setup_directories():
    """í•„ìš”í•œ ë””ë ‰í† ë¦¬ë“¤ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    directories = [
        config.DATA_DIR,
        config.RESULTS_DIR,
        "personalized_DB"  # VLM ìº¡ì…˜ ì €ì¥ìš© ë””ë ‰í† ë¦¬ ì¶”ê°€
    ]
    
    for directory in directories:
        if directory:  # ë¹ˆ ë¬¸ìì—´ì´ ì•„ë‹Œ ê²½ìš°ë§Œ
            os.makedirs(directory, exist_ok=True)
            print(f"âœ“ Created directory: {directory}")


def initialize_system():
    """ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    print("=" * 60)
    print("ğŸš€ Image Search System Initialization (Without Similar Examples)")
    print("=" * 60)
    
    # ë””ë ‰í† ë¦¬ ì„¤ì •
    setup_directories()
    
    # Hugging Face í† í° ì„¤ì •
    print("\n--- Step 0: Hugging Face Authentication ---")
    config.setup_huggingface_token()
    
    # ëœë¤ ì‹œë“œ ì„¤ì •
    config.set_random_seed()
    
    # GPU ë©”ëª¨ë¦¬ ì„¤ì •
    config.setup_gpu_memory()
    
    # ë°ì´í„°ì…‹ ë¡œë“œ ë° ë¶„ë¦¬
    print("\n--- Step 1: Loading and Splitting Dataset ---")
    dataset_loader = load_and_split_dataset()
    
    # í›ˆë ¨ ë°ì´í„°ì™€ ì‹¤í—˜ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    training_data = dataset_loader.get_training_data()
    experiment_data = dataset_loader.get_experiment_data()
    
    print(f"âœ“ Training data: {len(training_data)} samples")
    print(f"âœ“ Experiment data: {len(experiment_data)} samples")
    
    # ì´ë¯¸ì§€ ì„ë² ë”© DB êµ¬ì¶•
    print("\n--- Step 2: Building Image Embedding Database ---")
    image_embedding_db = build_image_embedding_db(training_data)
    
    # ë°ì´í„°ë² ì´ìŠ¤ ë§¤ë‹ˆì € ì´ˆê¸°í™”
    print("\n--- Step 3: Initializing Database Manager ---")
    db_manager = create_database_manager()
    db_manager.set_image_embedding_db(image_embedding_db)
    
    # ìº¡ì…˜ DB ì´ˆê¸°í™”
    initialize_databases_from_training_data(training_data, db_manager)
    
    # ê¸°ì¡´ my_captions.jsonê³¼ caption_embeddings.json ë¡œë“œ (ìˆëŠ” ê²½ìš°)
    print("\n--- Step 4: Loading Existing Generated Captions ---")
    try:
        # ê¸°ì¡´ ìƒì„±ëœ ìº¡ì…˜ ë¡œë“œ
        my_caption_loaded = db_manager.my_caption_db.load_db()
        if my_caption_loaded:
            print(f"âœ“ Loaded existing my_captions.json: {db_manager.my_caption_db.size()} captions")
        else:
            print("  No existing my_captions.json found - starting fresh")
        
        # ê¸°ì¡´ ìº¡ì…˜ ì„ë² ë”© ë¡œë“œ
        caption_embedding_loaded = db_manager.caption_embedding_db.load_db()
        if caption_embedding_loaded:
            print(f"âœ“ Loaded existing caption_embeddings.json: {db_manager.caption_embedding_db.size()} embeddings")
        else:
            print("  No existing caption_embeddings.json found - starting fresh")
            
    except Exception as e:
        print(f"  Warning: Could not load existing files: {e}")
        print("  Starting with empty my_caption and caption_embedding databases")
    
    # ë°ì´í„°ë² ì´ìŠ¤ ë™ê¸°í™” í™•ì¸
    print("\n--- Step 5: Database Synchronization Check ---")
    db_manager.sync_databases()
    
    print("\nâœ… System initialization completed successfully!")
    print("=" * 60)
    
    return dataset_loader, db_manager


class VLMCaptionManager:
    """VLM ìº¡ì…˜ì„ ëˆ„ì  ì €ì¥í•˜ê³  ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.vlm_captions_file = os.path.join("personalized_DB", "VLM_captions_wosimilar.json")
        self.captions = {}
        self.metadata = {}
        self.total_captions = 0
        self.load_existing_captions()
    
    def load_existing_captions(self):
        """ê¸°ì¡´ VLM ìº¡ì…˜ íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
        if os.path.exists(self.vlm_captions_file):
            try:
                with open(self.vlm_captions_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.captions = data.get("captions", {})
                    self.metadata = data.get("metadata", {})
                    self.total_captions = len(self.captions)  # ì‹¤ì œ ìº¡ì…˜ ê°œìˆ˜ë¡œ ê³„ì‚°
                    print(f"âœ“ Loaded existing VLM captions: {self.total_captions} entries")
            except Exception as e:
                print(f"  Warning: Could not load existing VLM captions: {e}")
                self.captions = {}
                self.metadata = {}
                self.total_captions = 0
        else:
            print("  No existing VLM captions found - starting fresh")
    
    def add_caption(self, index, caption, metadata):
        """ìƒˆë¡œìš´ ìº¡ì…˜ì„ ì¶”ê°€í•©ë‹ˆë‹¤."""
        self.captions[str(index)] = caption
        self.metadata[str(index)] = metadata
        self.total_captions = len(self.captions)
    
    def save_captions(self):
        """VLM ìº¡ì…˜ì„ íŒŒì¼ì— ì €ì¥í•©ë‹ˆë‹¤."""
        vlm_data = {
            "captions": self.captions,
            "metadata": self.metadata,
            "total_captions": self.total_captions
        }
        
        with open(self.vlm_captions_file, 'w', encoding='utf-8') as f:
            json.dump(vlm_data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ“ VLM captions saved: {self.vlm_captions_file} ({self.total_captions} total entries)")
        return self.vlm_captions_file
    
    def get_next_index(self):
        """ë‹¤ìŒ ì‚¬ìš©í•  ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        if not self.captions:
            return 7691  # VLM_captions.jsonê³¼ ë™ì¼í•œ ì‹œì‘ ì¸ë±ìŠ¤
        
        existing_indices = [int(k) for k in self.captions.keys()]
        return max(existing_indices) + 1




def get_simple_prompt():
    """ìœ ì‚¬ ì˜ˆì‹œ ì—†ì´ ì‚¬ìš©í•  ê°„ë‹¨í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return "Based on these similar image captions above, please generate an accurate and detailed caption for the input image. The caption should be in English"


def run_experiment(dataset_loader, db_manager, vlm_captioner, vlm_caption_manager, experiment_index: int = None):
    """ì‹¤í—˜ì„ ì‹¤í–‰í•©ë‹ˆë‹¤ (ìœ ì‚¬ ì˜ˆì‹œ ì—†ì´)."""
    if experiment_index is None:
        experiment_index = config.EXPERIMENT_IMAGE_INDEX
    
    print(f"\nğŸ” Running Experiment with Image Index: {experiment_index}")
    print("=" * 60)
    
    # ì‹¤í—˜ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    experiment_data = dataset_loader.get_experiment_data()
    
    if experiment_index >= len(experiment_data):
        raise ValueError(f"Experiment index {experiment_index} out of range. Max: {len(experiment_data) - 1}")
    
    # ì‹¤í—˜ ì´ë¯¸ì§€ ì •ë³´
    query_image = experiment_data[experiment_index]['image']
    query_info = {
        'experiment_index': experiment_index,
        'original_index': experiment_data[experiment_index].get('original_index', experiment_index),
        'caption': experiment_data[experiment_index].get('caption', 'No caption available')
    }
    
    print(f"Query Image Info:")
    print(f"  - Experiment Index: {query_info['experiment_index']}")
    print(f"  - Original Index: {query_info['original_index']}")
    print(f"  - Original Caption: {query_info['caption']}")
    
    # Step 1: VLMìœ¼ë¡œ ìº¡ì…˜ ìƒì„± (ìœ ì‚¬ ì˜ˆì‹œ ì—†ì´)
    print("\n--- Step 1: Generating Caption with VLM (No Similar Examples) ---")
    simple_prompt = get_simple_prompt()
    
    print(f"Using prompt: {simple_prompt}")
    
    generated_caption = vlm_captioner.generate_caption(
        image=query_image,
        prompt=simple_prompt,
        max_new_tokens=config.MAX_LENGTH,
        temperature=config.TEMPERATURE
    )
    
    print(f"Generated Caption: {generated_caption}")
    
    # Step 2: ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ DBì— ì¶”ê°€
    print("\n--- Step 2: Adding New Data to Databases ---")
    
    # VLM ìº¡ì…˜ ë§¤ë‹ˆì €ì—ì„œ ë‹¤ìŒ ì¸ë±ìŠ¤ ê°€ì ¸ì˜¤ê¸°
    new_index = vlm_caption_manager.get_next_index()
    
    print(f"  - New VLM caption index: {new_index}")
    
    # ì´ë¯¸ì§€ ì„ë² ë”© ìƒì„±
    from image_embedder import create_image_embedder
    image_embedder = create_image_embedder()
    new_image_embedding = image_embedder.embed_image(query_image)
    
    # ìº¡ì…˜ ì„ë² ë”© ìƒì„± (ìƒì„±ëœ ìº¡ì…˜ë§Œ)
    from caption_embedder import create_caption_embedder
    caption_embedder = create_caption_embedder()
    new_caption_embedding = caption_embedder.embed_caption(generated_caption)
    
    # ë©”íƒ€ë°ì´í„° ìƒì„±
    metadata = {
        'original_experiment_index': experiment_index,
        'original_index': query_info['original_index'],
        'original_caption': query_info['caption'],
        'generation_timestamp': datetime.now().isoformat(),
        'method': 'without_similar_examples',
        'prompt_used': simple_prompt
    }
    
    # DBì— ì¶”ê°€ (ê¸°ì¡´ ë°©ì‹ ìœ ì§€)
    db_manager.add_new_data(
        index=new_index,
        image_embedding=new_image_embedding.tolist(),
        caption=generated_caption,
        caption_embedding=new_caption_embedding.tolist(),
        metadata=metadata
    )
    
    # VLM ìº¡ì…˜ ë§¤ë‹ˆì €ì— ì¶”ê°€
    vlm_caption_manager.add_caption(new_index, generated_caption, metadata)
    
    print(f"âœ“ New data added with index: {new_index}")
    
    # Step 3: ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
    print("\n--- Step 3: Saving Updated Databases ---")
    db_manager.save_all_databases()
    
    # Step 4: VLM ìº¡ì…˜ ëˆ„ì  ì €ì¥
    print("\n--- Step 4: Saving Accumulated VLM Captions ---")
    vlm_caption_manager.save_captions()
    
    print("\nâœ… Experiment completed successfully!")
    print("=" * 60)
    
    return {
        'experiment_index': experiment_index,
        'new_vlm_index': new_index,
        'generated_caption': generated_caption,
        'original_caption': query_info['caption'],
        'success': True
    }


def run_all_experiments(dataset_loader, db_manager, vlm_captioner):
    """0~399ê¹Œì§€ ëª¨ë“  ì‹¤í—˜ì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    print("\nğŸ”„ Starting Sequential Experiments (0~399) - Without Similar Examples")
    print("=" * 60)
    
    # VLM ìº¡ì…˜ ë§¤ë‹ˆì € ì´ˆê¸°í™”
    vlm_caption_manager = VLMCaptionManager()
    
    experiment_data = dataset_loader.get_experiment_data()
    total_experiments = len(experiment_data)
    
    print(f"Total experiments to run: {total_experiments}")
    print(f"Starting from VLM caption index: {vlm_caption_manager.get_next_index()}")
    
    results_summary = []
    
    for i in range(total_experiments):
        print(f"\nğŸ“Š Running Experiment {i+1}/{total_experiments} (Index: {i})")
        print("-" * 50)
        
        try:
            # ê° ì‹¤í—˜ ì‹¤í–‰
            experiment_result = run_experiment(dataset_loader, db_manager, vlm_captioner, vlm_caption_manager, experiment_index=i)
            
            # ê²°ê³¼ ìš”ì•½ ì €ì¥
            summary = {
                'experiment_index': i,
                'success': True,
                'new_vlm_index': experiment_result['new_vlm_index'],
                'generated_caption': experiment_result['generated_caption'],
                'original_caption': experiment_result['original_caption'],
                'timestamp': datetime.now().isoformat()
            }
            results_summary.append(summary)
            
            print(f"âœ… Experiment {i} completed (VLM Index: {experiment_result['new_vlm_index']})")
            
            # GPU ë©”ëª¨ë¦¬ ì •ë¦¬ (CUDA ì‚¬ìš© ì‹œ)
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                
        except Exception as e:
            print(f"âŒ Experiment {i} failed: {e}")
            summary = {
                'experiment_index': i,
                'success': False,
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
            results_summary.append(summary)
            continue
    
    # í†µê³„ ì¶œë ¥
    successful = sum(1 for r in results_summary if r['success'])
    failed = total_experiments - successful
    
    print(f"\nğŸ“ˆ Experiments Summary:")
    print(f"  - Total: {total_experiments}")
    print(f"  - Successful: {successful}")
    print(f"  - Failed: {failed}")
    print(f"  - Success Rate: {successful/total_experiments*100:.1f}%")
    print(f"  - Final VLM captions count: {vlm_caption_manager.total_captions}")
    
    return results_summary


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        dataset_loader, db_manager = initialize_system()
        
        # VLM ìº¡ì…”ë„ˆ ì´ˆê¸°í™” (í•œ ë²ˆë§Œ ë¡œë“œ)
        print("\n--- Step 6: Initializing VLM Captioner ---")
        vlm_captioner = create_vlm_captioner()
        print("âœ“ VLM Captioner initialized")
        
        # ëª¨ë“  ì‹¤í—˜ ìˆœì°¨ ì‹¤í–‰
        results_summary = run_all_experiments(dataset_loader, db_manager, vlm_captioner)
        
        print(f"\nğŸ‰ All experiments completed!")
        
        # ìµœì¢… ë°ì´í„°ë² ì´ìŠ¤ í†µê³„
        print("\nğŸ“Š Final Database Statistics:")
        stats = db_manager.get_database_stats()
        for db_name, count in stats.items():
            print(f"  - {db_name}: {count} entries")
        
    except Exception as e:
        print(f"\nâŒ Error occurred: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
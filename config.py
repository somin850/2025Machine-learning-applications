# ğŸ“„ config.py
"""
Image Search í”„ë¡œì íŠ¸ ì„¤ì • íŒŒì¼
"""

import torch
import random
import os

# --- Hugging Face í† í° ì„¤ì • ---
# í™˜ê²½ë³€ìˆ˜ì—ì„œ í† í°ì„ ê°€ì ¸ì˜¤ê±°ë‚˜ ì§ì ‘ ì„¤ì •
HUGGINGFACE_TOKEN = os.getenv('HUGGINGFACE_TOKEN', None)
# ë˜ëŠ” ì§ì ‘ í† í°ì„ ì…ë ¥í•˜ì„¸ìš” (ë³´ì•ˆìƒ í™˜ê²½ë³€ìˆ˜ ì‚¬ìš© ê¶Œì¥):


# í† í°ì´ í•„ìš”í•œ ëª¨ë¸ë“¤
MODELS_REQUIRING_TOKEN = [
    "google/embeddinggemma-300m",
    "HuggingFaceTB/SmolVLM-Instruct"
]

# --- ë°ì´í„°ì…‹ ì„¤ì • ---
DATASET_NAME = "Naveengo/flickr8k"
DATASET_SPLIT = "train"

# ì‹¤í—˜ìš© ë°ì´í„° ë¶„ë¦¬ ì„¤ì •
TOTAL_SAMPLES = None  # Noneì´ë©´ ì „ì²´ ë°ì´í„°ì…‹ ì‚¬ìš©
EXPERIMENT_SAMPLES = 400  # ì‹¤í—˜ìš©ìœ¼ë¡œ ë¶„ë¦¬í•  ìƒ˜í”Œ ìˆ˜
RANDOM_SEED = 42  # ê³ ì •ëœ ì‹œë“œë¡œ ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼

# ì‹¤í—˜ ì„¤ì •
EXPERIMENT_IMAGE_INDEX = 1  # ì‹¤í—˜ì— ì‚¬ìš©í•  ì´ë¯¸ì§€ ì¸ë±ìŠ¤ (0~399)
TOP_K_SIMILAR = 5  # ìœ ì‚¬í•œ ì´ë¯¸ì§€ ìƒìœ„ Kê°œ

# --- ëª¨ë¸ ì„¤ì • ---
# CLIP ëª¨ë¸ (ì´ë¯¸ì§€ ì„ë² ë”©ìš©)
CLIP_MODEL_NAME = "openai/clip-vit-base-patch32"
# CLIP_MODEL_NAME = "openai/clip-vit-large-patch14"  # ë” ì •í™•í•˜ì§€ë§Œ í° ëª¨ë¸
# CLIP_MODEL_NAME = "google/siglip-base-patch16-224"  # SigLIP (ì„±ëŠ¥ ìš°ìˆ˜)

# VLM ëª¨ë¸ (ìº¡ì…˜ ìƒì„±ìš©) - SmolVLM ì‚¬ìš©
VLM_MODEL_NAME = "HuggingFaceTB/SmolVLM-Instruct"  # SmolVLM 2B, íš¨ìœ¨ì ì´ê³  ê°•ë ¥í•œ VLM
# VLM_MODEL_NAME = "Salesforce/blip-image-captioning-large"  # ê¸°ì¡´ BLIP ëª¨ë¸
# VLM_MODEL_NAME = "microsoft/git-large-coco"  # ëŒ€ì•ˆ VLM ëª¨ë¸

# Caption Embedding ëª¨ë¸ (í…ìŠ¤íŠ¸ ê²€ìƒ‰ìš©) - EmbeddingGemma ì‚¬ìš©
CAPTION_EMBEDDING_MODEL = "google/embeddinggemma-300m"  # Google EmbeddingGemma 300M (ìµœì‹ , ë‹¤êµ­ì–´ ì§€ì›)
# CAPTION_EMBEDDING_MODEL = "BAAI/bge-large-en-v1.5"  # BGE ëª¨ë¸ (ì„±ëŠ¥ ìš°ìˆ˜)
# CAPTION_EMBEDDING_MODEL = "BAAI/bge-base-en-v1.5"  # ë” ê°€ë²¼ìš´ ë²„ì „
# CAPTION_EMBEDDING_MODEL = "sentence-transformers/all-mpnet-base-v2"  # ëŒ€ì•ˆ

# --- ìƒì„± ì˜µì…˜ ---
MAX_LENGTH = 50
NUM_BEAMS = 4
TEMPERATURE = 0.7

# --- íŒŒì¼ ê²½ë¡œ ì„¤ì • ---
# ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ë“¤ (í˜„ì¬ ë””ë ‰í† ë¦¬ì— ì €ì¥)
IMAGE_EMBEDDING_DB = "image_embeddings.json"
CAPTION_DB = "captions.json"  # ì›ë³¸ Flickr8K ìº¡ì…˜ë§Œ
MY_CAPTION_DB = "my_captions.json"  # ìƒì„±ëœ ìº¡ì…˜ë§Œ
CAPTION_EMBEDDING_DB = "caption_embeddings.json"  # My Captionë§Œ ì„ë² ë”©

# ì‹¤í—˜ ë°ì´í„° íŒŒì¼ë“¤ (data í´ë”ì— ì €ì¥)
DATA_DIR = "data"
EXPERIMENT_DATA = f"{DATA_DIR}/experiment_data.json"
TRAINING_DATA = f"{DATA_DIR}/training_data.json"

# ê²°ê³¼ íŒŒì¼ë“¤ (results í´ë”ì— ì €ì¥)
RESULTS_DIR = "results"
SIMILARITY_RESULTS = f"{RESULTS_DIR}/similarity_results.json"
GENERATED_CAPTIONS = f"{RESULTS_DIR}/generated_captions.json"

# --- ì¥ì¹˜ ì„¤ì • ---
# GPU ì„¤ì • (A100 80GB MIG3g-40GB ìµœì í™”)
FORCE_CPU = False  # Trueë¡œ ì„¤ì •í•˜ë©´ ê°•ì œë¡œ CPU ì‚¬ìš©
GPU_MEMORY_FRACTION = 0.9  # GPU ë©”ëª¨ë¦¬ ì‚¬ìš© ë¹„ìœ¨ (90%)
MIXED_PRECISION = True  # í˜¼í•© ì •ë°€ë„ ì‚¬ìš© (A100ì—ì„œ ì„±ëŠ¥ í–¥ìƒ)

def get_device():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ì¥ì¹˜ (GPU ë˜ëŠ” CPU)ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if FORCE_CPU:
        print("ğŸ–¥ï¸  Using CPU (forced)")
        return torch.device("cpu")
    
    if torch.cuda.is_available():
        device = torch.device("cuda")
        gpu_name = torch.cuda.get_device_name(0)
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)  # GB
        print(f"ğŸš€ Using GPU: {gpu_name} ({gpu_memory:.1f}GB)")
        
        # A100 GPU ìµœì í™” ì„¤ì •
        if "A100" in gpu_name:
            print("âš¡ A100 GPU detected - enabling optimizations")
            torch.backends.cudnn.benchmark = True  # A100ì—ì„œ ì„±ëŠ¥ í–¥ìƒ
            if MIXED_PRECISION:
                print("  - Mixed precision enabled")
        
        return device
    else:
        print("ğŸ–¥ï¸  Using CPU (CUDA not available)")
        return torch.device("cpu")

def setup_gpu_memory():
    """GPU ë©”ëª¨ë¦¬ ì„¤ì •ì„ ìµœì í™”í•©ë‹ˆë‹¤."""
    if torch.cuda.is_available() and not FORCE_CPU:
        # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
        torch.cuda.empty_cache()
        
        # ë©”ëª¨ë¦¬ í• ë‹¹ ì „ëµ ì„¤ì • (A100 ìµœì í™”)
        torch.cuda.set_per_process_memory_fraction(GPU_MEMORY_FRACTION)
        print(f"ğŸ”§ GPU memory fraction set to {GPU_MEMORY_FRACTION*100}%")

# --- ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ---
def set_random_seed(seed: int = None):
    """ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ìœ„í•œ ëœë¤ ì‹œë“œ ì„¤ì •"""
    if seed is None:
        seed = RANDOM_SEED
    
    random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
    
    # ì¶”ê°€ì ì¸ ì¬í˜„ì„±ì„ ìœ„í•œ ì„¤ì •
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

def setup_huggingface_token():
    """Hugging Face í† í°ì„ ì„¤ì •í•©ë‹ˆë‹¤."""
    if HUGGINGFACE_TOKEN:
        try:
            from huggingface_hub import login
            login(token=HUGGINGFACE_TOKEN)
            print("âœ“ Hugging Face token configured successfully.")
            return True
        except ImportError:
            print("âš  Warning: huggingface_hub not installed. Installing...")
            try:
                import subprocess
                subprocess.check_call(["pip", "install", "huggingface_hub"])
                from huggingface_hub import login
                login(token=HUGGINGFACE_TOKEN)
                print("âœ“ Hugging Face token configured successfully.")
                return True
            except Exception as e:
                print(f"âŒ Failed to install huggingface_hub: {e}")
                return False
        except Exception as e:
            print(f"âŒ Failed to login with Hugging Face token: {e}")
            return False
    else:
        print("âš  Warning: No Hugging Face token found.")
        print("  Some models may require authentication.")
        print("  Set HUGGINGFACE_TOKEN environment variable or update config.py")
        return False

def check_model_access(model_name: str):
    """ëª¨ë¸ ì ‘ê·¼ ê¶Œí•œì„ í™•ì¸í•©ë‹ˆë‹¤."""
    if any(required_model in model_name for required_model in MODELS_REQUIRING_TOKEN):
        if not HUGGINGFACE_TOKEN:
            print(f"âš  Warning: Model '{model_name}' may require Hugging Face token.")
            print("  Please set your token in config.py or environment variable.")
            return False
    return True

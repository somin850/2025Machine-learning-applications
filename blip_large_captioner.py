# ğŸ“„ blip_large_captioner.py
"""
BLIP Large ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ 400ê°œ ì‹¤í—˜ ì´ë¯¸ì§€ì˜ ìº¡ì…˜ì„ ìƒì„±í•©ë‹ˆë‹¤.
ê²°ê³¼ëŠ” blip_large_captions.json íŒŒì¼ì— ì €ì¥ë©ë‹ˆë‹¤.
"""

import os
import json
from datetime import datetime
from PIL import Image
import torch
from transformers import BlipProcessor, BlipForConditionalGeneration
import config
from dataset_loader import Flickr8KLoader

class BlipLargeCaptioner:
    """BLIP Large ëª¨ë¸ì„ ì‚¬ìš©í•œ ìº¡ì…˜ ìƒì„±ê¸°"""
    
    def __init__(self, device=None):
        """
        BlipLargeCaptioner ì´ˆê¸°í™”
        
        Args:
            device: ì‚¬ìš©í•  ì¥ì¹˜ (cuda ë˜ëŠ” cpu)
        """
        if device is None:
            device = config.get_device()
        
        self.device = device
        self.model_name = "Salesforce/blip-image-captioning-large"
        
        print(f"Loading BLIP Large model: {self.model_name} on {device}...")
        
        # ëª¨ë¸ê³¼ í”„ë¡œì„¸ì„œ ë¡œë“œ
        self.processor = BlipProcessor.from_pretrained(self.model_name)
        
        # Large ëª¨ë¸ì€ ë©”ëª¨ë¦¬ë¥¼ ë§ì´ ì‚¬ìš©í•˜ë¯€ë¡œ ìµœì í™” ì„¤ì •
        if device.type == 'cuda':
            print("  - Enabling GPU optimizations for Large model")
            self.model = BlipForConditionalGeneration.from_pretrained(
                self.model_name,
                torch_dtype=torch.float16,  # FP16ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½
                low_cpu_mem_usage=True
            )
        else:
            self.model = BlipForConditionalGeneration.from_pretrained(self.model_name)
        
        self.model.to(device)
        self.model.eval()
        
        print("BLIP Large model loaded successfully.")
    
    def generate_caption(self, image, max_length=70, num_beams=5):
        """
        ë‹¨ì¼ ì´ë¯¸ì§€ì— ëŒ€í•œ ìº¡ì…˜ì„ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            image: PIL Image ê°ì²´ ë˜ëŠ” ì´ë¯¸ì§€ ê²½ë¡œ
            max_length: ìµœëŒ€ ìº¡ì…˜ ê¸¸ì´ (Large ëª¨ë¸ì€ ë” ê¸´ ìº¡ì…˜ ìƒì„± ê°€ëŠ¥)
            num_beams: ë¹” ì„œì¹˜ í¬ê¸° (Large ëª¨ë¸ì€ ë” ë§ì€ ë¹” ì‚¬ìš©)
            
        Returns:
            str: ìƒì„±ëœ ìº¡ì…˜
        """
        # ì´ë¯¸ì§€ ë¡œë“œ
        if isinstance(image, str):
            image = Image.open(image).convert('RGB')
        elif not isinstance(image, Image.Image):
            raise ValueError("image must be PIL Image or image path")
        
        # ì…ë ¥ ì „ì²˜ë¦¬
        inputs = self.processor(image, return_tensors="pt").to(self.device)
        
        # GPUì—ì„œ FP16 ì‚¬ìš© ì‹œ ì…ë ¥ë„ ë³€í™˜
        if self.device.type == 'cuda':
            for key in inputs:
                if inputs[key].dtype == torch.float32:
                    inputs[key] = inputs[key].half()
        
        # ìº¡ì…˜ ìƒì„±
        with torch.no_grad():
            generated_ids = self.model.generate(
                **inputs,
                max_length=max_length,
                num_beams=num_beams,
                early_stopping=True,
                do_sample=False,
                length_penalty=1.0,  # Large ëª¨ë¸ì—ì„œ ë” ìì„¸í•œ ìº¡ì…˜ ìƒì„±
                repetition_penalty=1.2
            )
        
        # í…ìŠ¤íŠ¸ ë””ì½”ë”©
        caption = self.processor.decode(generated_ids[0], skip_special_tokens=True)
        
        return caption
    
    def generate_captions_for_experiments(self, experiment_data, output_file="blip_large_captions.json"):
        """
        ì‹¤í—˜ ë°ì´í„°ì˜ ëª¨ë“  ì´ë¯¸ì§€ì— ëŒ€í•œ ìº¡ì…˜ì„ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            experiment_data: ì‹¤í—˜ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            output_file: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            dict: ìƒì„±ëœ ìº¡ì…˜ ë°ì´í„°
        """
        print(f"\nğŸ¯ Generating captions for {len(experiment_data)} experiment images...")
        print(f"Model: {self.model_name}")
        print(f"Output file: {output_file}")
        print("=" * 60)
        
        captions_data = {
            "captions": {},
            "metadata": {},
            "total_captions": 0,
            "model_info": {
                "model_name": self.model_name,
                "generation_timestamp": datetime.now().isoformat(),
                "total_experiments": len(experiment_data),
                "model_size": "large",
                "optimization": "fp16" if self.device.type == 'cuda' else "fp32"
            }
        }
        
        for i, item in enumerate(experiment_data):
            try:
                print(f"\nğŸ“¸ Processing experiment {i}/{len(experiment_data)-1} (Index: {i})")
                
                # ì´ë¯¸ì§€ ë¡œë“œ
                image = item['image']
                original_caption = item['caption']
                original_index = item['original_index']
                
                # ìº¡ì…˜ ìƒì„± (Large ëª¨ë¸ì€ ë” ê¸´ ìº¡ì…˜ê³¼ ë” ë§ì€ ë¹” ì‚¬ìš©)
                generated_caption = self.generate_caption(image, max_length=70, num_beams=5)
                
                print(f"  Original: {original_caption}")
                print(f"  Generated: {generated_caption}")
                
                # ë°ì´í„° ì €ì¥
                experiment_index = str(i)  # ì‹¤í—˜ ì¸ë±ìŠ¤ë¥¼ í‚¤ë¡œ ì‚¬ìš©
                
                captions_data["captions"][experiment_index] = generated_caption
                captions_data["metadata"][experiment_index] = {
                    "experiment_index": i,
                    "original_index": original_index,
                    "original_caption": original_caption,
                    "generation_timestamp": datetime.now().isoformat(),
                    "model_name": self.model_name,
                    "model_size": "large"
                }
                
                # GPU ë©”ëª¨ë¦¬ ì •ë¦¬ (Large ëª¨ë¸ì€ ë” ìì£¼ ì •ë¦¬)
                if self.device.type == 'cuda':
                    torch.cuda.empty_cache()
                
                # ì§„í–‰ë¥  í‘œì‹œ
                if (i + 1) % 50 == 0:
                    print(f"  ğŸ“Š Progress: {i+1}/{len(experiment_data)} ({(i+1)/len(experiment_data)*100:.1f}%)")
                
            except Exception as e:
                print(f"âŒ Error processing experiment {i}: {e}")
                # Large ëª¨ë¸ì—ì„œ ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ ì •ë¦¬
                if self.device.type == 'cuda':
                    torch.cuda.empty_cache()
                continue
        
        # ì´ ìº¡ì…˜ ìˆ˜ ì—…ë°ì´íŠ¸
        captions_data["total_captions"] = len(captions_data["captions"])
        
        # íŒŒì¼ ì €ì¥
        print(f"\nğŸ’¾ Saving results to {output_file}...")
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(captions_data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… Successfully generated {captions_data['total_captions']} captions")
        print(f"ğŸ“ Results saved to: {output_file}")
        
        return captions_data


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        # GPU ë©”ëª¨ë¦¬ ì„¤ì •
        config.setup_gpu_memory()
        
        print("ğŸš€ BLIP Large Caption Generation")
        print("=" * 60)
        
        # ë°ì´í„°ì…‹ ë¡œë” ì´ˆê¸°í™”
        print("\n--- Step 1: Loading Dataset ---")
        dataset_loader = Flickr8KLoader()
        dataset_loader.load_dataset()
        dataset_loader.load_split_data()
        
        # ì‹¤í—˜ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        experiment_data = dataset_loader.get_experiment_data()
        print(f"âœ“ Loaded {len(experiment_data)} experiment images")
        
        # BLIP Large ìº¡ì…”ë„ˆ ì´ˆê¸°í™”
        print("\n--- Step 2: Initializing BLIP Large Model ---")
        captioner = BlipLargeCaptioner()
        
        # ìº¡ì…˜ ìƒì„±
        print("\n--- Step 3: Generating Captions ---")
        results = captioner.generate_captions_for_experiments(
            experiment_data, 
            output_file="blip_large_captions.json"
        )
        
        print(f"\nğŸ‰ BLIP Large caption generation completed!")
        print(f"ğŸ“Š Statistics:")
        print(f"  - Total experiments: {len(experiment_data)}")
        print(f"  - Successful captions: {results['total_captions']}")
        print(f"  - Success rate: {results['total_captions']/len(experiment_data)*100:.1f}%")
        
        # ìµœì¢… GPU ë©”ëª¨ë¦¬ ì •ë¦¬
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            print(f"ğŸ§¹ GPU memory cleared")
        
    except Exception as e:
        print(f"\nâŒ Error occurred: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()

# üìÑ vit_gpt2_captioner.py
"""
ViT-GPT2 Î™®Îç∏ÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ 400Í∞ú Ïã§Ìóò Ïù¥ÎØ∏ÏßÄÏùò Ï∫°ÏÖòÏùÑ ÏÉùÏÑ±Ìï©ÎãàÎã§.
Í≤∞Í≥ºÎäî vit_gpt2_captions.json ÌååÏùºÏóê Ï†ÄÏû•Îê©ÎãàÎã§.
"""

import os
import json
from datetime import datetime
from PIL import Image
import torch
from transformers import VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer
import config
from dataset_loader import Flickr8KLoader

# OpenMP Ïò§Î•ò Ìï¥Í≤∞
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'

class ViTGPT2Captioner:
    """ViT-GPT2 Î™®Îç∏ÏùÑ ÏÇ¨Ïö©Ìïú Ï∫°ÏÖò ÏÉùÏÑ±Í∏∞"""
    
    def __init__(self, device=None):
        """
        ViTGPT2Captioner Ï¥àÍ∏∞Ìôî
        
        Args:
            device: ÏÇ¨Ïö©Ìï† Ïû•Ïπò (cuda ÎòêÎäî cpu)
        """
        if device is None:
            device = config.get_device()
        
        self.device = device
        self.model_name = "nlpconnect/vit-gpt2-image-captioning"
        # Mixed precision ÏÑ§Ï†ï Ï†ÄÏû•
        self.use_mixed_precision = getattr(config, 'USE_MIXED_PRECISION', True)
        
        print(f"Loading ViT-GPT2 model: {self.model_name} on {device}...")
        
        try:
            # Î™®Îç∏, ÌîÑÎ°úÏÑ∏ÏÑú, ÌÜ†ÌÅ¨ÎÇòÏù¥Ï†Ä Î°úÎìú
            self.model = VisionEncoderDecoderModel.from_pretrained(self.model_name)
            self.feature_extractor = ViTImageProcessor.from_pretrained(self.model_name)
            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
            
            # GPU ÏµúÏ†ÅÌôî ÏÑ§Ï†ï
            if device.type == 'cuda':
                print("  - Enabling GPU optimizations for ViT-GPT2 model")
                self.model = self.model.to(device)
                if self.use_mixed_precision:
                    self.model = self.model.half()  # FP16ÏúºÎ°ú Î©îÎ™®Î¶¨ Ï†àÏïΩ
                    print("  - Mixed precision (FP16) enabled")
            else:
                self.model = self.model.to(device)
            
            self.model.eval()
            
            # ÏÉùÏÑ± ÏÑ§Ï†ï
            self.max_length = 16
            self.num_beams = 4
            
            print("ViT-GPT2 model loaded successfully.")
            
        except Exception as e:
            print(f"‚ùå Failed to load ViT-GPT2 model: {e}")
            print("üí° Possible solutions:")
            print("  1. Check internet connection")
            print("  2. Install required packages: pip install transformers torch pillow")
            raise
    
    def generate_caption(self, image, max_length=None, num_beams=None):
        """
        Îã®Ïùº Ïù¥ÎØ∏ÏßÄÏóê ÎåÄÌïú Ï∫°ÏÖòÏùÑ ÏÉùÏÑ±Ìï©ÎãàÎã§.
        
        Args:
            image: PIL Image Í∞ùÏ≤¥ ÎòêÎäî Ïù¥ÎØ∏ÏßÄ Í≤ΩÎ°ú
            max_length: ÏµúÎåÄ Ï∫°ÏÖò Í∏∏Ïù¥
            num_beams: Îπî ÏÑúÏπò ÌÅ¨Í∏∞
            
        Returns:
            str: ÏÉùÏÑ±Îêú Ï∫°ÏÖò
        """
        # Í∏∞Î≥∏Í∞í ÏÑ§Ï†ï
        if max_length is None:
            max_length = self.max_length
        if num_beams is None:
            num_beams = self.num_beams
        
        # Ïù¥ÎØ∏ÏßÄ Î°úÎìú
        if isinstance(image, str):
            image = Image.open(image).convert('RGB')
        elif not isinstance(image, Image.Image):
            raise ValueError("image must be PIL Image or image path")
        
        # Ïù¥ÎØ∏ÏßÄ Ï†ÑÏ≤òÎ¶¨
        pixel_values = self.feature_extractor(images=image, return_tensors="pt").pixel_values
        pixel_values = pixel_values.to(self.device)
        
        # GPUÏóêÏÑú FP16 ÏÇ¨Ïö© Ïãú ÏûÖÎ†•ÎèÑ Î≥ÄÌôò
        if self.device.type == 'cuda' and self.use_mixed_precision:
            pixel_values = pixel_values.half()
        
        # Ï∫°ÏÖò ÏÉùÏÑ±
        with torch.no_grad():
            output_ids = self.model.generate(
                pixel_values,
                max_length=max_length,
                num_beams=num_beams,
                return_dict_in_generate=True,
                do_sample=False,
                early_stopping=True
            ).sequences
        
        # ÌÖçÏä§Ìä∏ ÎîîÏΩîÎî©
        caption = self.tokenizer.decode(output_ids[0], skip_special_tokens=True)
        
        return caption.strip()
    
    def generate_captions_for_experiments(self, experiment_data, output_file="vit_gpt2_captions.json"):
        """
        Ïã§Ìóò Îç∞Ïù¥ÌÑ∞Ïùò Î™®Îì† Ïù¥ÎØ∏ÏßÄÏóê ÎåÄÌïú Ï∫°ÏÖòÏùÑ ÏÉùÏÑ±Ìï©ÎãàÎã§.
        
        Args:
            experiment_data: Ïã§Ìóò Îç∞Ïù¥ÌÑ∞ Î¶¨Ïä§Ìä∏
            output_file: Ï∂úÎ†• ÌååÏùº Í≤ΩÎ°ú
            
        Returns:
            dict: ÏÉùÏÑ±Îêú Ï∫°ÏÖò Îç∞Ïù¥ÌÑ∞
        """
        print(f"\nüéØ Generating captions for {len(experiment_data)} experiment images...")
        print(f"Model: {self.model_name}")
        print(f"Output file: {output_file}")
        print("=" * 60)
        
        # Í∏∞Ï°¥ ÌååÏùºÏù¥ ÏûàÏúºÎ©¥ Î°úÎìúÌïòÏó¨ Ïù¥Ïñ¥ÏÑú ÏûëÏóÖ
        captions_data = {
            "captions": {},
            "metadata": {},
            "total_captions": 0,
            "model_info": {
                "model_name": self.model_name,
                "generation_timestamp": datetime.now().isoformat(),
                "total_experiments": len(experiment_data),
                "model_type": "vit-gpt2",
                "max_length": self.max_length,
                "num_beams": self.num_beams
            }
        }
        
        # Í∏∞Ï°¥ ÌååÏùº Î°úÎìú (ÏûàÎäî Í≤ΩÏö∞)
        if os.path.exists(output_file):
            print(f"Loading existing captions from {output_file}...")
            try:
                with open(output_file, 'r', encoding='utf-8') as f:
                    existing_data = json.load(f)
                    captions_data['captions'] = {str(k): v for k, v in existing_data.get('captions', {}).items()}
                    captions_data['metadata'] = {str(k): v for k, v in existing_data.get('metadata', {}).items()}
                    captions_data['total_captions'] = existing_data.get('total_captions', 0)
                print(f"‚úì Loaded {captions_data['total_captions']} existing captions.")
            except Exception as e:
                print(f"‚ö† Error loading existing captions: {e}. Starting fresh.")
                captions_data['captions'] = {}
                captions_data['metadata'] = {}
                captions_data['total_captions'] = 0
        
        successful_captions = 0
        failed_captions = 0
        
        for i, item in enumerate(experiment_data):
            try:
                # Ïù¥ÎØ∏ Ï∫°ÏÖòÏù¥ ÏÉùÏÑ±Îêú Í≤ΩÏö∞ Í±¥ÎÑàÎõ∞Í∏∞
                if str(i) in captions_data['captions']:
                    print(f"  Skipping experiment {i}: caption already exists.")
                    continue
                
                print(f"\nüì∏ Processing experiment {i}/{len(experiment_data)-1} (Index: {i})")
                
                # Ïù¥ÎØ∏ÏßÄ Î°úÎìú
                image = item['image']
                original_caption = item['caption']
                original_index = item['original_index']
                
                # Ï∫°ÏÖò ÏÉùÏÑ±
                generated_caption = self.generate_caption(image)
                
                print(f"  Original: {original_caption}")
                print(f"  Generated: {generated_caption}")
                
                # Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû•
                captions_data["captions"][str(i)] = generated_caption
                captions_data["metadata"][str(i)] = {
                    "experiment_index": i,
                    "original_index": original_index,
                    "original_caption": original_caption,
                    "generation_timestamp": datetime.now().isoformat(),
                    "model_name": self.model_name,
                    "model_type": "vit-gpt2"
                }
                
                successful_captions += 1
                
                # Ï§ëÍ∞Ñ Ï†ÄÏû• (50Í∞úÎßàÎã§)
                if (i + 1) % 50 == 0:
                    captions_data["total_captions"] = len(captions_data["captions"])
                    with open(output_file, 'w', encoding='utf-8') as f:
                        json.dump(captions_data, f, ensure_ascii=False, indent=2)
                    print(f"  üìä Progress: {i+1}/{len(experiment_data)} ({(i+1)/len(experiment_data)*100:.1f}%)")
                    print(f"  üíæ Intermediate save completed")
                
                # GPU Î©îÎ™®Î¶¨ Ï†ïÎ¶¨
                if self.device.type == 'cuda':
                    torch.cuda.empty_cache()
                
            except Exception as e:
                print(f"‚ùå Error processing experiment {i}: {e}")
                failed_captions += 1
                
                # GPU Î©îÎ™®Î¶¨ Ï†ïÎ¶¨
                if self.device.type == 'cuda':
                    torch.cuda.empty_cache()
                continue
        
        # Ï¥ù Ï∫°ÏÖò Ïàò ÏóÖÎç∞Ïù¥Ìä∏
        captions_data["total_captions"] = len(captions_data["captions"])
        
        # ÏµúÏ¢Ö ÌååÏùº Ï†ÄÏû•
        print(f"\nüíæ Saving final results to {output_file}...")
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(captions_data, f, ensure_ascii=False, indent=2)
        
        print(f"‚úÖ Caption generation completed!")
        print(f"üìä Results:")
        print(f"  - Total experiments: {len(experiment_data)}")
        print(f"  - Successful captions: {successful_captions}")
        print(f"  - Failed captions: {failed_captions}")
        print(f"  - Total captions in file: {captions_data['total_captions']}")
        print(f"üìÅ Results saved to: {output_file}")
        
        return captions_data


def main():
    """Î©îÏù∏ Ìï®Ïàò"""
    try:
        print("üöÄ ViT-GPT2 Caption Generation")
        print("=" * 60)
        
        # Îç∞Ïù¥ÌÑ∞ÏÖã Î°úÎçî Ï¥àÍ∏∞Ìôî
        print("\n--- Step 1: Loading Dataset ---")
        dataset_loader = Flickr8KLoader()
        
        # Îç∞Ïù¥ÌÑ∞ÏÖã Î°úÎìú
        print("  Loading Flickr8K dataset...")
        dataset_loader.load_dataset()
        print(f"  ‚úì Dataset loaded: {len(dataset_loader.dataset) if dataset_loader.dataset else 0} total samples")
        
        # Îç∞Ïù¥ÌÑ∞ Î∂ÑÌï† Î°úÎìú
        print("  Loading split data...")
        dataset_loader.load_split_data()
        
        # Ïã§Ìóò Îç∞Ïù¥ÌÑ∞ Í∞ÄÏ†∏Ïò§Í∏∞
        experiment_data = dataset_loader.get_experiment_data()
        print(f"‚úì Loaded {len(experiment_data)} experiment images")
        
        # Ïã§Ìóò Îç∞Ïù¥ÌÑ∞Í∞Ä ÎπÑÏñ¥ÏûàÎäîÏßÄ ÌôïÏù∏
        if len(experiment_data) == 0:
            print("‚ùå No experiment data found!")
            print("üí° Possible solutions:")
            print("  1. Check if data/experiment_data.json exists")
            print("  2. Run main.py first to initialize the system")
            print("  3. Check dataset loading configuration")
            return
        
        # ViT-GPT2 Ï∫°ÏÖîÎÑà Ï¥àÍ∏∞Ìôî
        print("\n--- Step 2: Initializing ViT-GPT2 Model ---")
        captioner = ViTGPT2Captioner()
        
        # Ï∫°ÏÖò ÏÉùÏÑ±
        print("\n--- Step 3: Generating Captions ---")
        results = captioner.generate_captions_for_experiments(
            experiment_data, 
            output_file="vit_gpt2_captions.json"
        )
        
        print(f"\nüéâ ViT-GPT2 caption generation completed!")
        print(f"üìä Statistics:")
        print(f"  - Total experiments: {len(experiment_data)}")
        print(f"  - Successful captions: {results['total_captions']}")
        
        # ZeroDivisionError Î∞©ÏßÄ
        if len(experiment_data) > 0:
            success_rate = results['total_captions']/len(experiment_data)*100
            print(f"  - Success rate: {success_rate:.1f}%")
        else:
            print(f"  - Success rate: N/A (no experiments)")
        
        # ÏµúÏ¢Ö GPU Î©îÎ™®Î¶¨ Ï†ïÎ¶¨
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            print(f"üßπ GPU memory cleared")
        
    except Exception as e:
        print(f"\n‚ùå Error occurred: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()

# ğŸ“„ dataset_loader.py
"""
Flickr8K ë°ì´í„°ì…‹ ë¡œë” ëª¨ë“ˆ
ì‹¤í—˜ìš© ë°ì´í„°ì™€ í›ˆë ¨ìš© ë°ì´í„°ë¥¼ ë¶„ë¦¬í•˜ì—¬ ë¡œë“œí•©ë‹ˆë‹¤.
"""

import json
import os
from datasets import load_dataset
from PIL import Image
import config
import random
from typing import Tuple, List, Dict


class Flickr8KLoader:
    """Flickr8K ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ê³  ì‹¤í—˜ìš©/í›ˆë ¨ìš©ìœ¼ë¡œ ë¶„ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self):
        """Flickr8KLoader ì´ˆê¸°í™”"""
        self.dataset = None
        self.experiment_data = []
        self.training_data = []
        
        # ëœë¤ ì‹œë“œ ì„¤ì •
        config.set_random_seed()
    
    def load_dataset(self):
        """Flickr8K ë°ì´í„°ì…‹ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
        print(f"Loading dataset: {config.DATASET_NAME}...")
        
        try:
            if config.TOTAL_SAMPLES:
                dataset_split = f"{config.DATASET_SPLIT}[:{config.TOTAL_SAMPLES}]"
            else:
                dataset_split = config.DATASET_SPLIT
            
            self.dataset = load_dataset(config.DATASET_NAME, split=dataset_split)
            print(f"Dataset loaded successfully. Total samples: {len(self.dataset)}")
            
        except Exception as e:
            print(f"Error loading dataset: {e}")
            raise
    
    def split_data(self):
        """ë°ì´í„°ë¥¼ ì‹¤í—˜ìš©ê³¼ í›ˆë ¨ìš©ìœ¼ë¡œ ë¶„ë¦¬í•©ë‹ˆë‹¤."""
        if self.dataset is None:
            raise ValueError("Dataset not loaded. Call load_dataset() first.")
        
        print(f"Splitting data: {config.EXPERIMENT_SAMPLES} for experiment, rest for training...")
        
        # ì „ì²´ ì¸ë±ìŠ¤ ìƒì„±
        total_indices = list(range(len(self.dataset)))
        
        # ì‹¤í—˜ìš© ì¸ë±ìŠ¤ ëœë¤ ì„ íƒ (ê³ ì •ëœ ì‹œë“œë¡œ)
        experiment_indices = random.sample(total_indices, config.EXPERIMENT_SAMPLES)
        experiment_indices.sort()  # ì •ë ¬í•˜ì—¬ ì¼ê´€ì„± ìœ ì§€
        
        # í›ˆë ¨ìš© ì¸ë±ìŠ¤ (ì‹¤í—˜ìš© ì œì™¸)
        training_indices = [i for i in total_indices if i not in experiment_indices]
        
        # ë°ì´í„° ë¶„ë¦¬
        self.experiment_data = []
        self.training_data = []
        
        # ë°ì´í„°ì…‹ êµ¬ì¡° í™•ì¸
        if len(self.dataset) > 0:
            sample_item = self.dataset[0]
            print(f"Dataset fields: {list(sample_item.keys())}")
            
            # ìº¡ì…˜ í•„ë“œëª… í™•ì¸ (Flickr8KëŠ” 'text' í•„ë“œ ì‚¬ìš©)
            caption_field = None
            possible_caption_fields = ['text', 'caption', 'captions', 'sentence', 'description']
            for field in possible_caption_fields:
                if field in sample_item:
                    caption_field = field
                    break
            
            if caption_field is None:
                raise ValueError(f"No caption field found. Available fields: {list(sample_item.keys())}")
            
            print(f"Using caption field: '{caption_field}'")
        
        for idx in experiment_indices:
            item = self.dataset[idx]
            # ìº¡ì…˜ì´ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ì²« ë²ˆì§¸ ìº¡ì…˜ ì‚¬ìš©
            caption = item[caption_field]
            if isinstance(caption, list):
                caption = caption[0] if caption else ""
            
            self.experiment_data.append({
                'original_index': idx,
                'image': item['image'],
                'caption': caption
            })
        
        for i, idx in enumerate(training_indices):
            item = self.dataset[idx]
            # ìº¡ì…˜ì´ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ì²« ë²ˆì§¸ ìº¡ì…˜ ì‚¬ìš©
            caption = item[caption_field]
            if isinstance(caption, list):
                caption = caption[0] if caption else ""
                
            self.training_data.append({
                'training_index': i,  # í›ˆë ¨ ë°ì´í„° ë‚´ì—ì„œì˜ ì¸ë±ìŠ¤
                'original_index': idx,  # ì›ë³¸ ë°ì´í„°ì…‹ì—ì„œì˜ ì¸ë±ìŠ¤
                'image': item['image'],
                'caption': caption
            })
        
        print(f"Data split completed:")
        print(f"  - Experiment data: {len(self.experiment_data)} samples")
        print(f"  - Training data: {len(self.training_data)} samples")
    
    def save_split_data(self):
        """ë¶„ë¦¬ëœ ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
        os.makedirs(os.path.dirname(config.EXPERIMENT_DATA), exist_ok=True)
        os.makedirs(os.path.dirname(config.TRAINING_DATA), exist_ok=True)
        
        # ì‹¤í—˜ ë°ì´í„° ì €ì¥ (ì´ë¯¸ì§€ëŠ” ê²½ë¡œë§Œ ì €ì¥)
        experiment_save_data = []
        for item in self.experiment_data:
            experiment_save_data.append({
                'experiment_index': len(experiment_save_data),  # ì‹¤í—˜ ë°ì´í„° ë‚´ì—ì„œì˜ ì¸ë±ìŠ¤
                'original_index': item['original_index'],
                'caption': item['caption']
            })
        
        with open(config.EXPERIMENT_DATA, 'w', encoding='utf-8') as f:
            json.dump(experiment_save_data, f, ensure_ascii=False, indent=2)
        
        # í›ˆë ¨ ë°ì´í„° ì €ì¥ (ì´ë¯¸ì§€ëŠ” ê²½ë¡œë§Œ ì €ì¥)
        training_save_data = []
        for item in self.training_data:
            training_save_data.append({
                'training_index': item['training_index'],
                'original_index': item['original_index'],
                'caption': item['caption']
            })
        
        with open(config.TRAINING_DATA, 'w', encoding='utf-8') as f:
            json.dump(training_save_data, f, ensure_ascii=False, indent=2)
        
        print(f"Split data saved:")
        print(f"  - Experiment data: {config.EXPERIMENT_DATA}")
        print(f"  - Training data: {config.TRAINING_DATA}")
    
    def load_split_data(self):
        """ì €ì¥ëœ ë¶„ë¦¬ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
        if os.path.exists(config.EXPERIMENT_DATA) and os.path.exists(config.TRAINING_DATA):
            print("Loading existing split data...")
            
            with open(config.EXPERIMENT_DATA, 'r', encoding='utf-8') as f:
                experiment_save_data = json.load(f)
            
            with open(config.TRAINING_DATA, 'r', encoding='utf-8') as f:
                training_save_data = json.load(f)
            
            # ì›ë³¸ ë°ì´í„°ì…‹ì—ì„œ ì´ë¯¸ì§€ ì •ë³´ ë³µì›
            self.experiment_data = []
            for item in experiment_save_data:
                original_item = self.dataset[item['original_index']]
                self.experiment_data.append({
                    'experiment_index': item['experiment_index'],
                    'original_index': item['original_index'],
                    'image': original_item['image'],
                    'caption': item['caption']
                })
            
            self.training_data = []
            for item in training_save_data:
                original_item = self.dataset[item['original_index']]
                self.training_data.append({
                    'training_index': item['training_index'],
                    'original_index': item['original_index'],
                    'image': original_item['image'],
                    'caption': item['caption']
                })
            
            print(f"Split data loaded:")
            print(f"  - Experiment data: {len(self.experiment_data)} samples")
            print(f"  - Training data: {len(self.training_data)} samples")
            
            return True
        else:
            print("No existing split data found.")
            return False
    
    def get_experiment_image(self, index: int):
        """ì‹¤í—˜ìš© ì´ë¯¸ì§€ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        if not self.experiment_data:
            raise ValueError("Experiment data not loaded.")
        
        if index >= len(self.experiment_data):
            raise IndexError(f"Index {index} out of range. Max index: {len(self.experiment_data) - 1}")
        
        return self.experiment_data[index]
    
    def get_training_data(self):
        """í›ˆë ¨ìš© ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return self.training_data
    
    def get_experiment_data(self):
        """ì‹¤í—˜ìš© ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return self.experiment_data


def create_dataset_loader():
    """DatasetLoader ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•˜ëŠ” í¸ì˜ í•¨ìˆ˜"""
    return Flickr8KLoader()


def load_and_split_dataset():
    """ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ê³  ë¶„ë¦¬í•˜ëŠ” ì „ì²´ í”„ë¡œì„¸ìŠ¤"""
    loader = create_dataset_loader()
    
    # ë°ì´í„°ì…‹ ë¡œë“œ
    loader.load_dataset()
    
    # ê¸°ì¡´ ë¶„ë¦¬ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
    if not loader.load_split_data():
        # ì—†ìœ¼ë©´ ìƒˆë¡œ ë¶„ë¦¬
        loader.split_data()
        loader.save_split_data()
    
    return loader

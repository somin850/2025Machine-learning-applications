#!/usr/bin/env python3
"""
Query Maker - OpenAI GPT-4o-minië¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
ì´ë¯¸ì§€ì™€ ì›ë³¸ ìº¡ì…˜ì„ ê¸°ë°˜ìœ¼ë¡œ ì¸ê°„ì´ ì‹¤ì œ ê²€ìƒ‰í•  ë•Œ ì‚¬ìš©í•  ë²•í•œ ì¿¼ë¦¬ë¥¼ ìƒì„±
"""

import json
import os
import base64
import requests
import time
from typing import Dict, List, Optional
from datetime import datetime
from tqdm import tqdm
import argparse
from datasets import load_dataset
import config

# OpenAI API ì„¤ì •
OPENAI_API_KEY = "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"
OPENAI_API_URL = "https://api.openai.com/v1/chat/completions"

class QueryGenerator:
    """OpenAI GPT-4o-minië¥¼ ì‚¬ìš©í•œ ì¿¼ë¦¬ ìƒì„± í´ë˜ìŠ¤"""
    
    def __init__(self, api_key: str = OPENAI_API_KEY):
        """
        QueryGenerator ì´ˆê¸°í™”
        
        Args:
            api_key (str): OpenAI API í‚¤
        """
        self.api_key = api_key
        self.api_url = OPENAI_API_URL
        self.headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }
        self.dataset = None
        
        print(f"ğŸ¤– Initializing Query Generator with GPT-4o-mini")
    
    def load_huggingface_dataset(self):
        """Hugging Face ë°ì´í„°ì…‹ ë¡œë“œ"""
        if self.dataset is None:
            print(f"ğŸ“Š Loading Hugging Face dataset: {config.DATASET_NAME}...")
            try:
                if config.TOTAL_SAMPLES:
                    dataset_split = f"{config.DATASET_SPLIT}[:{config.TOTAL_SAMPLES}]"
                else:
                    dataset_split = config.DATASET_SPLIT
                
                self.dataset = load_dataset(config.DATASET_NAME, split=dataset_split)
                print(f"âœ… Dataset loaded successfully. Total samples: {len(self.dataset)}")
                
            except Exception as e:
                print(f"âŒ Error loading dataset: {e}")
                raise
        
    def encode_image_to_base64(self, image_path: str) -> str:
        """
        ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
        
        Args:
            image_path (str): ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            str: base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€ ë¬¸ìì—´
        """
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')
    
    def encode_pil_image_to_base64(self, pil_image) -> str:
        """
        PIL Imageë¥¼ base64ë¡œ ì¸ì½”ë”© (Hugging Face ë°ì´í„°ì…‹ìš©)
        
        Args:
            pil_image: PIL Image ê°ì²´
            
        Returns:
            str: base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€ ë¬¸ìì—´
        """
        import io
        buffer = io.BytesIO()
        pil_image.save(buffer, format="JPEG")
        return base64.b64encode(buffer.getvalue()).decode('utf-8')
    
    def create_search_query_prompt(self, caption: str) -> str:
        """
        ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„± (ì´ë¯¸ì§€ í¬í•¨)
        
        Args:
            caption (str): VLM ìƒì„± ìº¡ì…˜ ë˜ëŠ” ì›ë³¸ ìº¡ì…˜
            
        Returns:
            str: GPTì—ê²Œ ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸
        """
        prompt = f"""**System Role:**
You are a "Semantic Search Simulator" testing a high-performance AI photo gallery.
Your goal is to generate **highly specific, descriptive search queries** by directly analyzing the provided image.

**CRITICAL INSTRUCTION:**
You will receive an IMAGE and a CAPTION. You MUST:
1. **Carefully examine the image** to extract visual details that may not be in the caption
2. **Compare the image with the caption** to identify any missing or inaccurate details
3. **Generate a query that captures the most distinctive visual features** visible in the image

**Image Analysis Requirements:**
- **Look at colors carefully:** Note exact shades, patterns, and color combinations
- **Observe spatial relationships:** Positions, orientations, interactions between objects
- **Identify unique details:** Text, logos, specific clothing items, distinctive objects
- **Notice background elements:** Settings, environments, contextual details
- **Capture actions precisely:** Body positions, movements, expressions

**Query Generation Rules:**
1.  **Maximize Specificity:** Include multiple attributes for the main subject.
    * *Instead of:* "man in hat"
    * *Use:* "man in grey t-shirt wearing yellow paper bag hat with text Bite"
2.  **Mandatory Features:** You MUST include:
    * **Specific Colors:** Extract exact colors from the image (e.g., "black race car", "red and white striped shirt")
    * **Unique Actions:** Describe precise actions visible in the image (e.g., "being sprayed with water", "jumping off a dock")
    * **Distinct Objects/Context:** Note text, logos, specific items visible in the image (e.g., "American flag backpack", "words Bite on hat")
    * **Visual Details:** Include details you can see but might not be in the caption
3.  **Phrasing Style:**
    * Do NOT write full grammatical sentences (No "In this image there is...")
    * Write a **Dense Descriptive Phrase** (Noun + Adjectives + Prepositional phrases)
    * Target length: **6 to 12 words** (Keep it concise but distinctive)

**Examples:**

* **Input Caption:** "A man in an orange hat starring at something ."
    * **Output Query:** man in orange hat
    * *(Reasoning: "Orange hat" is the key identifier.)*

* **Input Caption:** "A brown dog is running through neck-deep water carrying a tennis ball ."
    * **Output Query:** brown dog with tennis ball
    * *(Reasoning: "Brown", "water", and "tennis ball" are distinct features.)*

* **Input Caption:** "A boy in a striped shirt is jumping in front of a water fountain ."
    * **Output Query:** boy in striped shirt jumping
    * *(Reasoning: "Striped shirt" distinguishes him from other boys.)*

* **Input Caption:** "A black and white dog catches a toy in midair ."
    * **Output Query:** black and white dog catching toy
    * *(Reasoning: The color pattern "black and white" is crucial.)*

**Reference Caption:**
"{caption}"

**Your Task:**
1. Examine the image carefully
2. Identify the most distinctive visual features that would help find this specific image
3. Generate a search query that combines:
   - Information from the caption (if accurate)
   - Additional visual details you observe in the image
   - Unique characteristics that distinguish this image from similar ones

**Output:**
(Print ONLY the search query phrase, no explanations.):"""

        return prompt
    
    def generate_query_from_image(self, image_path: str, original_caption: str, 
                                 max_retries: int = 3) -> Optional[str]:
        """
        ì´ë¯¸ì§€ì™€ ìº¡ì…˜ìœ¼ë¡œë¶€í„° ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
        
        Args:
            image_path (str): ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            original_caption (str): ì›ë³¸ ìº¡ì…˜
            max_retries (int): ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
            
        Returns:
            Optional[str]: ìƒì„±ëœ ê²€ìƒ‰ ì¿¼ë¦¬ ë˜ëŠ” None
        """
        if not os.path.exists(image_path):
            print(f"âŒ Image not found: {image_path}")
            return None
        
        try:
            # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
            base64_image = self.encode_image_to_base64(image_path)
            
            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self.create_search_query_prompt(original_caption)
            
            # API ìš”ì²­ ë°ì´í„° êµ¬ì„±
            payload = {
                "model": "gpt-4o-mini",
                "messages": [
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": prompt
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{base64_image}",
                                    "detail": "high"
                                }
                            }
                        ]
                    }
                ],
                "max_tokens": 500,
                "temperature": 0.7
            }
            
            # API í˜¸ì¶œ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
            for attempt in range(max_retries):
                try:
                    response = requests.post(
                        OPENAI_API_URL,
                        headers=self.headers,
                        json=payload,
                        timeout=30
                    )
                    
                    if response.status_code == 200:
                        result = response.json()
                        query = result['choices'][0]['message']['content'].strip()
                        
                        # ë”°ì˜´í‘œ ì œê±° ë° ì •ë¦¬
                        query = query.strip('"\'')
                        
                        return query
                    else:
                        print(f"âš ï¸ API Error (attempt {attempt + 1}): {response.status_code}")
                        if attempt == max_retries - 1:
                            print(f"âŒ Failed after {max_retries} attempts: {response.text}")
                            return None
                        
                except requests.exceptions.RequestException as e:
                    print(f"âš ï¸ Request Error (attempt {attempt + 1}): {e}")
                    if attempt == max_retries - 1:
                        return None
                    
        except Exception as e:
            print(f"âŒ Error generating query for {image_path}: {e}")
            return None
    
    def generate_query_with_base64_image(self, base64_image: str, original_caption: str, debug: bool = False) -> Optional[str]:
        """
        base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€ì™€ ì›ë³¸ ìº¡ì…˜ìœ¼ë¡œë¶€í„° ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
        
        Args:
            base64_image (str): base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€
            original_caption (str): ì›ë³¸ ìº¡ì…˜
            debug (bool): ë””ë²„ê¹… ì •ë³´ ì¶œë ¥ ì—¬ë¶€
            
        Returns:
            Optional[str]: ìƒì„±ëœ ì¿¼ë¦¬ ë˜ëŠ” None
        """
        try:
            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self.create_search_query_prompt(original_caption)
            
            # ì´ë¯¸ì§€ í¬ê¸° í™•ì¸ (ë””ë²„ê¹…ìš©)
            if debug:
                image_size_kb = len(base64_image) * 3 / 4 / 1024  # base64ëŠ” ì•½ 33% ë” í¼
                print(f"   ğŸ“¸ Image size: {image_size_kb:.1f} KB (base64 encoded)")
                print(f"   ğŸ“ Caption: {original_caption[:60]}...")
                print(f"   ğŸ’¬ Prompt length: {len(prompt)} chars")
            
            # OpenAI API ìš”ì²­ ë°ì´í„° êµ¬ì„±
            # GPT-4o-miniëŠ” ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ë¥¼ í•¨ê»˜ ë°›ì„ ìˆ˜ ìˆìŒ
            data = {
                "model": "gpt-4o-mini",
                "messages": [
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": prompt
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{base64_image}"
                                }
                            }
                        ]
                    }
                ],
                "max_tokens": 100,
                "temperature": 0.7
            }
            
            if debug:
                print(f"   ğŸ“¤ Sending request to OpenAI API...")
                print(f"   ğŸ”— Image format: data:image/jpeg;base64,{base64_image[:50]}...")
            
            # API ìš”ì²­
            response = requests.post(self.api_url, headers=self.headers, json=data)
            
            if response.status_code == 200:
                result = response.json()
                query = result['choices'][0]['message']['content'].strip()
                return query
            else:
                print(f"âŒ API Error: {response.status_code} - {response.text}")
                return None
                
        except Exception as e:
            print(f"âŒ Error generating query: {e}")
            return None
    
    def generate_queries_from_dataset(self, dataset_path: str, image_dir: str, 
                                    output_file: str, max_queries: int = None, resume: bool = False,
                                    vlm_captions_path: str = None) -> Dict:
        """
        ë°ì´í„°ì…‹ìœ¼ë¡œë¶€í„° ì¿¼ë¦¬ë“¤ì„ ìƒì„±
        
        Args:
            dataset_path (str): ì‹¤í—˜ ë°ì´í„° JSON íŒŒì¼ ê²½ë¡œ
            image_dir (str): ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ê²½ë¡œ
            output_file (str): ì¶œë ¥ ì¿¼ë¦¬ JSON íŒŒì¼ ê²½ë¡œ
            max_queries (int): ìƒì„±í•  ìµœëŒ€ ì¿¼ë¦¬ ìˆ˜ (Noneì´ë©´ ì „ì²´)
            resume (bool): ê¸°ì¡´ íŒŒì¼ì—ì„œ ì´ì–´ì„œ ìƒì„±í• ì§€ ì—¬ë¶€
            vlm_captions_path (str): VLM ìº¡ì…˜ íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ ì›ë³¸ ìº¡ì…˜ ì‚¬ìš©)
            
        Returns:
            Dict: ìƒì„± í†µê³„
        """
        print(f"ğŸ“‚ Loading dataset from: {dataset_path}")
        
        # VLM ìº¡ì…˜ ë¡œë“œ (ìˆëŠ” ê²½ìš°)
        vlm_captions = {}
        if vlm_captions_path and os.path.exists(vlm_captions_path):
            print(f"ğŸ“‚ Loading VLM captions from: {vlm_captions_path}")
            with open(vlm_captions_path, 'r', encoding='utf-8') as f:
                vlm_data = json.load(f)
                vlm_captions = vlm_data.get('captions', {})
            print(f"   âœ… Loaded {len(vlm_captions)} VLM captions")
        else:
            print(f"   â„¹ï¸  Using original captions from experiment_data.json")
        
        # ë°ì´í„°ì…‹ ë¡œë“œ
        with open(dataset_path, 'r', encoding='utf-8') as f:
            dataset = json.load(f)
        
        if isinstance(dataset, list):
            experiments = dataset
        elif 'experiments' in dataset:
            experiments = dataset['experiments']
        else:
            experiments = list(dataset.values())
        
        # ì²˜ë¦¬í•  ì‹¤í—˜ ìˆ˜ ê²°ì •
        if max_queries:
            experiments = experiments[:max_queries]
        
        print(f"ğŸ“Š Processing {len(experiments)} experiments")
        
        # Rate limiting ì„¤ì • (1ë¶„ì— 30ê°œ = 2ì´ˆë‹¹ 1ê°œ)
        RATE_LIMIT_DELAY = 2.0  # ì´ˆ
        QUERIES_PER_MINUTE = 30
        print(f"â±ï¸  Rate limiting: {QUERIES_PER_MINUTE} queries/minute ({RATE_LIMIT_DELAY}s delay between queries)")
        
        # ê¸°ì¡´ ì¿¼ë¦¬ ë¡œë“œ (resume ëª¨ë“œì¸ ê²½ìš°)
        existing_queries = {}
        if resume and os.path.exists(output_file):
            try:
                with open(output_file, 'r', encoding='utf-8') as f:
                    existing_data = json.load(f)
                    existing_queries = existing_data.get('queries', {})
                print(f"ğŸ“‚ Loaded {len(existing_queries)} existing queries from {output_file}")
            except Exception as e:
                print(f"âš ï¸  Could not load existing queries: {e}")
        
        # ì¿¼ë¦¬ ìƒì„±
        queries = existing_queries.copy()  # ê¸°ì¡´ ì¿¼ë¦¬ë¡œ ì‹œì‘
        success_count = len(existing_queries)  # ê¸°ì¡´ ì„±ê³µ ê°œìˆ˜
        failed_count = 0
        skipped_count = 0
        
        # Hugging Face ë°ì´í„°ì…‹ ë¡œë“œ
        self.load_huggingface_dataset()
        
        for i, experiment in enumerate(tqdm(experiments, desc="Generating queries")):
            try:
                # experiment_data.jsonì—ì„œ ì •ë³´ ì¶”ì¶œ
                experiment_index = experiment.get('experiment_index', i)
                original_index = experiment.get('original_index', i)
                
                # VLM ìº¡ì…˜ ì‚¬ìš© (ìˆëŠ” ê²½ìš°), ì—†ìœ¼ë©´ ì›ë³¸ ìº¡ì…˜ ì‚¬ìš©
                if vlm_captions and str(experiment_index) in vlm_captions:
                    caption = vlm_captions[str(experiment_index)]
                    caption_source = "VLM"
                else:
                    caption = experiment.get('caption', '')
                    caption_source = "original"
                
                print(f"ğŸ” Processing experiment {experiment_index}: original_index={original_index} (caption: {caption_source})")
                
                # ì´ë¯¸ ìƒì„±ëœ ì¿¼ë¦¬ì¸ì§€ í™•ì¸ (resume ëª¨ë“œ)
                if str(experiment_index) in queries:
                    skipped_count += 1
                    if skipped_count % 20 == 0:  # 20ê°œë§ˆë‹¤ ì¶œë ¥
                        print(f"â­ï¸  Skipped {skipped_count} existing queries...")
                    continue
                
                # Hugging Face ë°ì´í„°ì…‹ì—ì„œ original_indexì— í•´ë‹¹í•˜ëŠ” ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°
                if original_index < len(self.dataset):
                    sample = self.dataset[original_index]
                    pil_image = sample['image']  # PIL Image ê°ì²´
                    
                    # PIL Imageë¥¼ base64ë¡œ ì¸ì½”ë”©
                    base64_image = self.encode_pil_image_to_base64(pil_image)
                    
                    # ì¿¼ë¦¬ ìƒì„± (ì´ë¯¸ì§€ + ìº¡ì…˜ ì‚¬ìš©)
                    query = self.generate_query_with_base64_image(base64_image, caption)
                else:
                    print(f"âš ï¸  Original index {original_index} out of range")
                    failed_count += 1
                    continue
                
                if query:
                    # experiment_indexë¥¼ í‚¤ë¡œ ì‚¬ìš© (0, 1, 2, ...)
                    queries[str(experiment_index)] = query
                    success_count += 1
                    
                    print(f"âœ… Generated query for experiment {experiment_index} (original_index={original_index}): {query[:50]}...")
                    
                    # ì§„í–‰ ìƒí™© ì¶œë ¥ (5ê°œë§ˆë‹¤)
                    if (i + 1) % 5 == 0:
                        print(f"   Progress: {i + 1}/{len(experiments)} - Success: {success_count}, Failed: {failed_count}")
                else:
                    failed_count += 1
                    print(f"   âŒ Failed to generate query for experiment {experiment_index}")
                
                # Rate limiting: 1ë¶„ì— 30ê°œ = 2ì´ˆë‹¹ 1ê°œ
                # (ê±´ë„ˆë›´ ì¿¼ë¦¬ëŠ” ë”œë ˆì´ ì—†ìŒ)
                if str(experiment_index) not in existing_queries:
                    time.sleep(RATE_LIMIT_DELAY)  # Rate limit ëŒ€ê¸°
                
            except Exception as e:
                failed_count += 1
                print(f"   âŒ Error processing experiment {i}: {e}")
                # ì—ëŸ¬ ë°œìƒ ì‹œì—ë„ rate limit ì¤€ìˆ˜ë¥¼ ìœ„í•´ ëŒ€ê¸°
                time.sleep(RATE_LIMIT_DELAY)
                continue
        
        # ê²°ê³¼ ì €ì¥
        query_data = {
            "queries": queries,
            "metadata": {
                "total_experiments": len(experiments),
                "successful_queries": success_count,
                "failed_queries": failed_count,
                "skipped_queries": skipped_count,
                "newly_generated": success_count - len(existing_queries),
                "success_rate": success_count / len(experiments) if experiments else 0,
                "generation_time": datetime.now().isoformat(),
                "model": "gpt-4o-mini",
                "dataset_source": dataset_path,
                "image_directory": image_dir,
                "vlm_captions_source": vlm_captions_path if vlm_captions_path else "original_captions",
                "caption_type": "VLM" if vlm_captions else "original",
                "resume_mode": resume
            }
        }
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„± (ë””ë ‰í† ë¦¬ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ)
        output_dir = os.path.dirname(output_file)
        if output_dir:  # ë””ë ‰í† ë¦¬ ê²½ë¡œê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ìƒì„±
            os.makedirs(output_dir, exist_ok=True)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(query_data, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ Queries saved to: {output_file}")
        
        # í†µê³„ ë°˜í™˜
        success_rate = success_count / len(experiments) if experiments else 0
        newly_generated = success_count - len(existing_queries)
        stats = {
            "total_experiments": len(experiments),
            "successful_queries": success_count,
            "failed_queries": failed_count,
            "skipped_queries": skipped_count,
            "newly_generated": newly_generated,
            "success_rate": success_rate,
            "output_file": output_file
        }
        
        print(f"\nğŸ“Š Generation Statistics:")
        print(f"   Total experiments: {stats['total_experiments']}")
        print(f"   Successful queries: {stats['successful_queries']}")
        print(f"   Failed queries: {stats['failed_queries']}")
        print(f"   Skipped (existing): {stats['skipped_queries']}")
        print(f"   Newly generated: {newly_generated}")
        print(f"   Success rate: {success_rate:.2%}")
        
        return stats

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="Generate search queries using GPT-4o-mini")
    parser.add_argument("--dataset", type=str, required=True,
                       help="Path to experiment dataset JSON file")
    parser.add_argument("--image_dir", type=str, required=True,
                       help="Directory containing images")
    parser.add_argument("--output", type=str, default="generated_queries.json",
                       help="Output query JSON file path")
    parser.add_argument("--max_queries", type=int, default=None,
                       help="Maximum number of queries to generate (default: all)")
    parser.add_argument("--api_key", type=str, default=OPENAI_API_KEY,
                       help="OpenAI API key")
    
    args = parser.parse_args()
    
    print("=" * 80)
    print("ğŸ¤– Search Query Generation with GPT-4o-mini")
    print("=" * 80)
    print(f"ğŸ“‚ Dataset: {args.dataset}")
    print(f"ğŸ–¼ï¸  Image directory: {args.image_dir}")
    print(f"ğŸ’¾ Output file: {args.output}")
    print(f"ğŸ”¢ Max queries: {args.max_queries or 'All'}")
    print()
    
    # ì…ë ¥ íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not os.path.exists(args.dataset):
        print(f"âŒ Dataset file not found: {args.dataset}")
        return
    
    if not os.path.exists(args.image_dir):
        print(f"âŒ Image directory not found: {args.image_dir}")
        return
    
    try:
        # ì¿¼ë¦¬ ìƒì„±ê¸° ì´ˆê¸°í™”
        generator = QueryGenerator(api_key=args.api_key)
        
        # ì¿¼ë¦¬ ìƒì„± ì‹¤í–‰
        stats = generator.generate_queries_from_dataset(
            dataset_path=args.dataset,
            image_dir=args.image_dir,
            output_file=args.output,
            max_queries=args.max_queries
        )
        
        if stats['successful_queries'] > 0:
            print(f"\nğŸ‰ Query generation completed!")
            print(f"   Generated {stats['successful_queries']} queries")
            print(f"   Success rate: {stats['success_rate']:.2%}")
        else:
            print(f"\nâŒ No queries were generated successfully!")
            
    except Exception as e:
        print(f"\nâŒ Error occurred: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()

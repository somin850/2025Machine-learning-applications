#!/usr/bin/env python3
"""
Personalized DB Structure - ê° ëª¨ë¸ë³„ ìº¡ì…˜ ì„ë² ë”© DB ìƒì„± ëª¨ë“ˆ
ê° ìº¡ì…˜ ìƒì„± ëª¨ë¸(BLIP-base, BLIP-large, ViT-GPT2, VLM)ì˜ ìº¡ì…˜ì„ ì„ë² ë”©í•˜ì—¬ DBë¡œ ì €ì¥
"""

import json
import os
import numpy as np
from typing import Dict, List, Tuple
from sentence_transformers import SentenceTransformer
import torch
from tqdm import tqdm

# ê¸°ë³¸ ì„¤ì •
EMBEDDING_MODEL = "google/embeddinggemma-300m"
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

class CaptionEmbeddingDB:
    """ìº¡ì…˜ ì„ë² ë”© ë°ì´í„°ë² ì´ìŠ¤ í´ë˜ìŠ¤"""
    
    def __init__(self, model_name: str = EMBEDDING_MODEL, device: str = DEVICE):
        """
        CaptionEmbeddingDB ì´ˆê¸°í™”
        
        Args:
            model_name (str): ì„ë² ë”© ëª¨ë¸ ì´ë¦„
            device (str): ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤
        """
        self.model_name = model_name
        self.device = device
        self.embedding_model = None
        self.embeddings = {}
        self.captions = {}
        
        print(f"ğŸš€ Initializing Caption Embedding DB")
        print(f"   Model: {model_name}")
        print(f"   Device: {device}")
        
    def load_embedding_model(self):
        """ì„ë² ë”© ëª¨ë¸ ë¡œë“œ"""
        if self.embedding_model is None:
            print(f"ğŸ“¥ Loading embedding model: {self.model_name}")
            
            # EmbeddingGemma ëª¨ë¸ ë¡œë“œ
            self.embedding_model = SentenceTransformer(
                self.model_name,
                device=self.device,
                trust_remote_code=True
            )
            
            # Mixed precision ì„¤ì • (A100 ìµœì í™”)
            if self.device == "cuda":
                self.embedding_model.half()
                print("   âš¡ Mixed precision enabled for A100 optimization")
            
            print("   âœ… Embedding model loaded successfully")
    
    def embed_caption(self, caption: str) -> np.ndarray:
        """
        ë‹¨ì¼ ìº¡ì…˜ì„ ì„ë² ë”©
        
        Args:
            caption (str): ì„ë² ë”©í•  ìº¡ì…˜
            
        Returns:
            np.ndarray: ì„ë² ë”© ë²¡í„°
        """
        if self.embedding_model is None:
            self.load_embedding_model()
        
        # EmbeddingGemmaëŠ” document embeddingì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ í¬ë§· ì‚¬ìš©
        formatted_caption = f"Represent this caption for retrieval: {caption}"
        
        with torch.no_grad():
            if self.device == "cuda":
                with torch.cuda.amp.autocast():
                    embedding = self.embedding_model.encode(
                        formatted_caption,
                        convert_to_numpy=True,
                        normalize_embeddings=True
                    )
            else:
                embedding = self.embedding_model.encode(
                    formatted_caption,
                    convert_to_numpy=True,
                    normalize_embeddings=True
                )
        
        return embedding
    
    def embed_captions_batch(self, captions: List[str], batch_size: int = 32) -> List[np.ndarray]:
        """
        ë°°ì¹˜ë¡œ ìº¡ì…˜ë“¤ì„ ì„ë² ë”©
        
        Args:
            captions (List[str]): ì„ë² ë”©í•  ìº¡ì…˜ ë¦¬ìŠ¤íŠ¸
            batch_size (int): ë°°ì¹˜ í¬ê¸°
            
        Returns:
            List[np.ndarray]: ì„ë² ë”© ë²¡í„° ë¦¬ìŠ¤íŠ¸
        """
        if self.embedding_model is None:
            self.load_embedding_model()
        
        # í”„ë¡¬í”„íŠ¸ í¬ë§·íŒ…
        formatted_captions = [f"Represent this caption for retrieval: {caption}" for caption in captions]
        
        embeddings = []
        
        print(f"ğŸ”„ Embedding {len(captions)} captions in batches of {batch_size}")
        
        for i in tqdm(range(0, len(formatted_captions), batch_size), desc="Embedding"):
            batch = formatted_captions[i:i + batch_size]
            
            with torch.no_grad():
                if self.device == "cuda":
                    with torch.cuda.amp.autocast():
                        batch_embeddings = self.embedding_model.encode(
                            batch,
                            convert_to_numpy=True,
                            normalize_embeddings=True,
                            batch_size=batch_size
                        )
                else:
                    batch_embeddings = self.embedding_model.encode(
                        batch,
                        convert_to_numpy=True,
                        normalize_embeddings=True,
                        batch_size=batch_size
                    )
            
            embeddings.extend(batch_embeddings)
            
            # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
            if self.device == "cuda":
                torch.cuda.empty_cache()
        
        return embeddings
    
    def build_db_from_json(self, json_file_path: str, output_file_path: str) -> Dict:
        """
        JSON íŒŒì¼ë¡œë¶€í„° ì„ë² ë”© DB ìƒì„±
        
        Args:
            json_file_path (str): ì…ë ¥ JSON íŒŒì¼ ê²½ë¡œ
            output_file_path (str): ì¶œë ¥ ì„ë² ë”© DB íŒŒì¼ ê²½ë¡œ
            
        Returns:
            Dict: ìƒì„±ëœ DB í†µê³„
        """
        print(f"\nğŸ“‚ Building embedding DB from: {json_file_path}")
        
        # JSON íŒŒì¼ ë¡œë“œ
        with open(json_file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        captions_dict = data.get('captions', {})
        
        if not captions_dict:
            raise ValueError(f"No captions found in {json_file_path}")
        
        print(f"   ğŸ“Š Found {len(captions_dict)} captions")
        
        # ìº¡ì…˜ ë¦¬ìŠ¤íŠ¸ì™€ ì¸ë±ìŠ¤ ì¤€ë¹„
        indices = []
        captions = []
        
        for idx_str, caption in captions_dict.items():
            indices.append(int(idx_str))
            captions.append(caption)
            self.captions[int(idx_str)] = caption
        
        # ë°°ì¹˜ ì„ë² ë”© ìˆ˜í–‰
        embeddings = self.embed_captions_batch(captions)
        
        # ì„ë² ë”© ì €ì¥
        for idx, embedding in zip(indices, embeddings):
            self.embeddings[idx] = embedding.tolist()
        
        # ê²°ê³¼ ì €ì¥
        db_data = {
            "model_info": {
                "embedding_model": self.model_name,
                "device": self.device,
                "total_captions": len(captions)
            },
            "embeddings": self.embeddings,
            "captions": self.captions
        }
        
        with open(output_file_path, 'w', encoding='utf-8') as f:
            json.dump(db_data, f, ensure_ascii=False, indent=2)
        
        print(f"   âœ… Embedding DB saved to: {output_file_path}")
        
        # í†µê³„ ë°˜í™˜
        stats = {
            "total_captions": len(captions),
            "embedding_dimension": len(embeddings[0]) if embeddings else 0,
            "model_name": self.model_name,
            "output_file": output_file_path
        }
        
        return stats

def process_all_caption_files():
    """ëª¨ë“  ìº¡ì…˜ íŒŒì¼ì„ ì²˜ë¦¬í•˜ì—¬ ì„ë² ë”© DB ìƒì„±"""
    
    # ì²˜ë¦¬í•  íŒŒì¼ ëª©ë¡
    caption_files = [
        {
            "input": "personalized_DB/blip_base_captions.json",
            "output": "personalized_DB_Embedding/blip_base_embeddings.json",
            "name": "BLIP-Base"
        },
        {
            "input": "personalized_DB/blip_large_captions.json", 
            "output": "personalized_DB_Embedding/blip_large_embeddings.json",
            "name": "BLIP-Large"
        },
        {
            "input": "personalized_DB/vit_gpt2_captions.json",
            "output": "personalized_DB_Embedding/vit_gpt2_embeddings.json", 
            "name": "ViT-GPT2"
        },
        {
            "input": "personalized_DB/VLM_captions.json",
            "output": "personalized_DB_Embedding/VLM_embeddings.json",
            "name": "VLM"
        },
        {
            "input": "personalized_DB/VLM_wosimilar_captions.json",
            "output": "personalized_DB_Embedding/VLM_wosimilar_embeddings.json",
            "name": "VLM-WoSimilar"
        }
    ]
    
    print("=" * 80)
    print("ğŸš€ Personalized Caption Embedding DB Generation")
    print("=" * 80)
    print(f"ğŸ“‹ Processing {len(caption_files)} caption files")
    print(f"ğŸ¤– Embedding Model: {EMBEDDING_MODEL}")
    print(f"ğŸ’» Device: {DEVICE}")
    print()
    
    all_stats = []
    
    for i, file_info in enumerate(caption_files, 1):
        print(f"\n{'='*20} [{i}/{len(caption_files)}] {file_info['name']} {'='*20}")
        
        # ì…ë ¥ íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not os.path.exists(file_info['input']):
            print(f"âŒ Input file not found: {file_info['input']}")
            continue
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(os.path.dirname(file_info['output']), exist_ok=True)
        
        try:
            # ì„ë² ë”© DB ìƒì„±
            db = CaptionEmbeddingDB()
            stats = db.build_db_from_json(file_info['input'], file_info['output'])
            stats['model_type'] = file_info['name']
            all_stats.append(stats)
            
            print(f"   ğŸ“Š Statistics:")
            print(f"      - Total captions: {stats['total_captions']}")
            print(f"      - Embedding dimension: {stats['embedding_dimension']}")
            print(f"      - Output file: {stats['output_file']}")
            
        except Exception as e:
            print(f"âŒ Error processing {file_info['name']}: {e}")
            import traceback
            traceback.print_exc()
            continue
    
    # ì „ì²´ í†µê³„ ì¶œë ¥
    print("\n" + "=" * 80)
    print("ğŸ“Š Final Statistics")
    print("=" * 80)
    
    for stats in all_stats:
        print(f"âœ… {stats['model_type']}")
        print(f"   - Captions: {stats['total_captions']}")
        print(f"   - Dimensions: {stats['embedding_dimension']}")
        print(f"   - File: {os.path.basename(stats['output_file'])}")
        print()
    
    print(f"ğŸ‰ Successfully processed {len(all_stats)}/{len(caption_files)} files!")
    
    return all_stats

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        # GPU ì •ë³´ ì¶œë ¥
        if torch.cuda.is_available():
            print(f"ğŸš€ CUDA Available: {torch.cuda.get_device_name()}")
            print(f"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
        else:
            print("ğŸ’» Using CPU")
        
        # ëª¨ë“  ìº¡ì…˜ íŒŒì¼ ì²˜ë¦¬
        stats = process_all_caption_files()
        
        if stats:
            print("\nâœ… All embedding databases created successfully!")
        else:
            print("\nâŒ No files were processed successfully!")
            
    except Exception as e:
        print(f"\nâŒ Error occurred: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
